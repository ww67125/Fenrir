mysq只能再配置文件中更改数据路径和临时文件路径 并需要将路径文件夹权限设为777


1. 目前最严重的问题是导入数据的单条数据相当大，一个sql内容很多，并且同时进行全文索引的增量，占用大量内存导致内存不够而数据库崩溃。
目前想到的解决方法：
  1. 如果可以就减少入库的文本内容
  2. 不使用mysql自带的全文索引，找另外一款全文索引每次导入数据后，定时更新全文索引。
  3. 将这个大字段从表中拆分成单独一张表，然后将数据拆分，一条拆成多条

2. mysql 最大允许sql的内容大小为1G，实际上没有超过这个值就会崩溃，是不是应该适当调小max_allowed_packet的大小,调成最大值并不好？

3. 查询重复数据的思路 使用重复字段进行group by 然后having count >1
使用聚合子句作为条件时 想进行更新删除操作应该以原始表套一层查询 比如 id in (select id from(select min(id) as id from table group by field having count(field)>1) as t)

4.简单去重语句思路 按重复字段只做group by聚合所有数据 查询min（id）或max（id）这样就会查出所有不重复数据 然后使用id not in 删除其他重复数据 比如
delete from table where id not in (select id from (select min(id) from table group by field) as t);

5. 当使用on duplicate key update 这样的语句时，更新操作会让last_insert_id()等于0
解决办法就是 写成 on duplicate key update id=last_insert_id(id) 使用 select @@IDENTITY 查询可以查出更新行id
