#### 使用bulk数据导入失败
可能原因：数据量过大，bulk默认最大数据量是100M
解决方案：在elasticsearch中添加配置
http.max_content_length : 500mb 来修改bulk允许的最大大小（有可能会导致速度降低）

#### 查询时如果未带分页条件，默认只查询10条数据
如果不指定分页条件，默认只有10条数据，指定分页条件，最大值也超不过设置的最大值

需要在索引配置中设置

index.max_result_window //用于索引搜索的 from+size 的最大值。默认为 10000

index.max_rescore_window // 在搜索此索引中 rescore 的 window_size 的最大值

也可以提前在logstash模板中配置
